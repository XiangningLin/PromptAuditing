# ğŸ† Benchmark ä½¿ç”¨æŒ‡å—
# Benchmark Usage Guide

## æ¦‚è¿° / Overview

æœ¬é¡¹ç›®æä¾›äº†å®Œæ•´çš„å¤šæ¨¡å‹ benchmark ç³»ç»Ÿï¼Œç”¨äºæµ‹è¯•å’Œæ¯”è¾ƒä¸åŒ AI æ¨¡å‹åœ¨ Prompt Auditing ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚

## æ”¯æŒçš„æ¨¡å‹æ€»æ•° / Total Supported Models

æ™ºå¢å¢å¹³å°æ”¯æŒ **40+ ä¸ªæ¨¡å‹**ï¼Œæ¶µç›–ä»¥ä¸‹æä¾›å•†ï¼š

### å›½é™…æ¨¡å‹ / International Models

#### OpenAI (6 models)
- `gpt-4o` - æœ€å¼ºå¤§çš„ GPT-4 ç‰ˆæœ¬
- `gpt-4o-mini` - æ›´å¿«é€Ÿç»æµçš„ç‰ˆæœ¬
- `gpt-4-turbo` - ä¸Šä¸€ä»£æ——èˆ°
- `gpt-4` - ç»å…¸ GPT-4
- `gpt-3.5-turbo` - å¿«é€Ÿé«˜æ•ˆ
- `gpt-3.5-turbo-16k` - é•¿ä¸Šä¸‹æ–‡ç‰ˆæœ¬

#### Anthropic (4 models)
- `claude-3-5-sonnet-20241022` - æœ€æ–° Sonnet
- `claude-3-opus-20240229` - æœ€å¼ºå¤§çš„ Claude
- `claude-3-sonnet-20240229` - å¹³è¡¡ç‰ˆæœ¬
- `claude-3-haiku-20240307` - æœ€å¿«çš„ Claude

#### Google (3 models)
- `gemini-1.5-pro` - æœ€å¼ºå¤§çš„ Gemini
- `gemini-1.5-flash` - å¿«é€Ÿç‰ˆæœ¬
- `gemini-pro` - ç»å…¸ç‰ˆæœ¬

#### Meta (2 models)
- `llama-3-70b` - å¤§å‚æ•°å¼€æºæ¨¡å‹
- `llama-3-8b` - å°å‚æ•°å¼€æºæ¨¡å‹

#### xAI (1 model)
- `grok-beta` - Elon Musk çš„ AI

### ä¸­å›½æ¨¡å‹ / Chinese Models

#### é˜¿é‡Œ Alibaba (4 models)
- `qwen-max` - é€šä¹‰åƒé—®æœ€å¼ºç‰ˆæœ¬
- `qwen-plus` - å¹³è¡¡æ€§èƒ½
- `qwen-turbo` - å¿«é€Ÿå“åº”
- `qwen-max-longcontext` - é•¿ä¸Šä¸‹æ–‡ç‰ˆæœ¬

#### ç™¾åº¦ Baidu (3 models)
- `ernie-bot-4` - æ–‡å¿ƒä¸€è¨€ 4.0
- `ernie-bot` - æ–‡å¿ƒä¸€è¨€æ ‡å‡†ç‰ˆ
- `ernie-bot-turbo` - æ–‡å¿ƒä¸€è¨€å¿«é€Ÿç‰ˆ

#### æ™ºè°± Zhipu (3 models)
- `glm-4` - ChatGLM-4
- `glm-4-plus` - ChatGLM-4 Plus
- `glm-3-turbo` - ChatGLM-3 Turbo

#### DeepSeek (2 models)
- `deepseek-chat` - é€šç”¨å¯¹è¯æ¨¡å‹
- `deepseek-coder` - ä»£ç ä¸“ç”¨æ¨¡å‹

#### å­—èŠ‚è·³åŠ¨ ByteDance (2 models)
- `doubao-pro-32k` - è±†åŒ… Pro
- `doubao-lite-32k` - è±†åŒ… Lite

#### ç™¾å· Baichuan (2 models)
- `baichuan2-turbo` - ç™¾å·2 Turbo
- `baichuan2-turbo-192k` - ç™¾å·2 é•¿ä¸Šä¸‹æ–‡

#### è®¯é£ iFlytek (2 models)
- `spark-3.5` - è®¯é£æ˜Ÿç« 3.5
- `spark-3.0` - è®¯é£æ˜Ÿç« 3.0

---

## å¿«é€Ÿå¼€å§‹ / Quick Start

### 1. æŸ¥çœ‹æ‰€æœ‰æ”¯æŒçš„æ¨¡å‹

```bash
python3 models_list.py
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
================================================================================
æ™ºå¢å¢æ”¯æŒçš„æ‰€æœ‰æ¨¡å‹ / All Zhizengzeng Supported Models
================================================================================

ã€OPENAIã€‘ (6 models)
--------------------------------------------------------------------------------
  â€¢ gpt-4o                                  | GPT-4o
  â€¢ gpt-4o-mini                             | GPT-4o Mini
  ...

ã€ANTHROPICã€‘ (4 models)
--------------------------------------------------------------------------------
  â€¢ claude-3-5-sonnet-20241022              | Claude 3.5 Sonnet
  ...

æ€»è®¡ / Total: 40+ ä¸ªæ¨¡å‹
```

### 2. è¿è¡Œ Benchmark æµ‹è¯•

#### é€‰é¡¹ Aï¼šæµ‹è¯•æ¨èçš„ä»£è¡¨æ€§æ¨¡å‹ï¼ˆæ¨èï¼‰

```bash
python3 benchmark.py --models benchmark
```

è¿™å°†æµ‹è¯• 12 ä¸ªç²¾é€‰çš„ä»£è¡¨æ€§æ¨¡å‹ï¼Œè¦†ç›–å„ä¸ªä¸»è¦æä¾›å•†ã€‚

#### é€‰é¡¹ Bï¼šæµ‹è¯•æ‰€æœ‰æ¨¡å‹ï¼ˆè€—æ—¶è¾ƒé•¿ï¼‰

```bash
python3 benchmark.py --models all --delay 2
```

âš ï¸ è­¦å‘Šï¼šè¿™å°†æµ‹è¯• 40+ ä¸ªæ¨¡å‹ï¼Œæ¯ä¸ªæ¨¡å‹æµ‹è¯• 3 ä¸ªæç¤ºè¯ï¼Œæ€»å…± 120+ æ¬¡ API è°ƒç”¨ï¼Œå¯èƒ½éœ€è¦ 10-20 åˆ†é’Ÿã€‚

#### é€‰é¡¹ Cï¼šåªæµ‹è¯•ç‰¹å®šç±»å‹çš„æ¨¡å‹

```bash
# åªæµ‹è¯• OpenAI æ¨¡å‹
python3 benchmark.py --models openai

# åªæµ‹è¯•ä¸­å›½æ¨¡å‹
python3 benchmark.py --models chinese
```

### 3. æŸ¥çœ‹ç»“æœ

Benchmark å®Œæˆåä¼šï¼š
1. åœ¨ç»ˆç«¯æ˜¾ç¤ºè¯¦ç»†æŠ¥å‘Š
2. ä¿å­˜ç»“æœåˆ° JSON æ–‡ä»¶ï¼š`benchmark_results_YYYYMMDD_HHMMSS.json`

---

## Benchmark æµ‹è¯•å†…å®¹ / What Gets Tested

æ¯ä¸ªæ¨¡å‹ä¼šç”¨ 3 ä¸ªä¸åŒçš„æµ‹è¯•æç¤ºè¯è¿›è¡Œæµ‹è¯•ï¼š

1. **Good Prompt** - ç¬¦åˆé“å¾·æ ‡å‡†çš„æç¤ºè¯ï¼ˆåº”è¯¥ PASSï¼‰
2. **Bad Prompt** - æ˜æ˜¾è¿åé“å¾·æ ‡å‡†çš„æç¤ºè¯ï¼ˆåº”è¯¥ FAILï¼‰
3. **Mixed Prompt** - æ··åˆè´¨é‡çš„æç¤ºè¯ï¼ˆå¯èƒ½ PASS æˆ– FAILï¼‰

### è¯„ä¼°æŒ‡æ ‡ / Evaluation Metrics

- **Success Rate** - API è°ƒç”¨æˆåŠŸç‡
- **Accuracy** - è¯„ä¼°å‡†ç¡®ç‡ï¼ˆèƒ½å¦æ­£ç¡®è¯†åˆ«å¥½/åæç¤ºè¯ï¼‰
- **Average Latency** - å¹³å‡å“åº”æ—¶é—´
- **Token Usage** - Token ä½¿ç”¨é‡

---

## ç»“æœç¤ºä¾‹ / Sample Results

```
æ¨¡å‹æ€§èƒ½å¯¹æ¯” / Model Performance Comparison:
--------------------------------------------------------------------------------
Model                          Success    Accuracy     Avg Latency     Tokens    
--------------------------------------------------------------------------------
GPT-4o                         3/3        3/3          2.34s           1250      
Claude 3.5 Sonnet              3/3        3/3          2.89s           1180      
é€šä¹‰åƒé—® Max                    3/3        2/3          1.56s           980       
GPT-3.5 Turbo                  3/3        2/3          0.98s           850       
...
```

---

## é«˜çº§ç”¨æ³• / Advanced Usage

### è‡ªå®šä¹‰æµ‹è¯•æç¤ºè¯

ç¼–è¾‘ `benchmark.py` ä¸­çš„ `TEST_PROMPTS` å­—å…¸ï¼š

```python
TEST_PROMPTS = {
    "custom1": "Your custom prompt here...",
    "custom2": "Another custom prompt...",
}
```

### è°ƒæ•´ API è°ƒç”¨å»¶è¿Ÿ

é¿å…è§¦å‘é€Ÿç‡é™åˆ¶ï¼š

```bash
python3 benchmark.py --delay 2.0  # æ¯æ¬¡è°ƒç”¨é—´éš” 2 ç§’
```

### åˆ†æç»“æœ

ç»“æœä¿å­˜åœ¨ JSON æ–‡ä»¶ä¸­ï¼Œå¯ä»¥ç”¨ Python è¿›ä¸€æ­¥åˆ†æï¼š

```python
import json

with open('benchmark_results_20251109_123456.json', 'r') as f:
    data = json.load(f)

# åˆ†ææ•°æ®
for result in data['results']:
    print(f"{result['model_name']}: {result['latency']}s")
```

---

## æ¨èçš„ Benchmark é…ç½® / Recommended Benchmark Setup

### å¿«é€Ÿæµ‹è¯•ï¼ˆ5 åˆ†é’Ÿï¼‰
```bash
python3 benchmark.py --models benchmark --delay 1
```
æµ‹è¯• 12 ä¸ªä»£è¡¨æ€§æ¨¡å‹

### å®Œæ•´æµ‹è¯•ï¼ˆ20 åˆ†é’Ÿï¼‰
```bash
python3 benchmark.py --models all --delay 2
```
æµ‹è¯•æ‰€æœ‰ 40+ ä¸ªæ¨¡å‹

### å¯¹æ¯”æµ‹è¯•
```bash
# æµ‹è¯•å›½é™…æ¨¡å‹
python3 benchmark.py --models openai --delay 1

# æµ‹è¯•ä¸­å›½æ¨¡å‹
python3 benchmark.py --models chinese --delay 1
```

---

## æ³¨æ„äº‹é¡¹ / Important Notes

### API é…ç½®

ç¡®ä¿ `.env` æ–‡ä»¶é…ç½®æ­£ç¡®ï¼š
```bash
OPENAI_API_KEY=sk-zk2a256993d569634deabbbcd007279f33f690e5aef05532
OPENAI_BASE_URL=https://api.zhizengzeng.com/v1/
```

### æˆæœ¬ä¼°ç®—

- æ¯ä¸ªæ¨¡å‹æµ‹è¯•ï¼š3 æ¬¡ API è°ƒç”¨
- æ¯æ¬¡è°ƒç”¨çº¦ï¼š500-2000 tokens
- æ¨è benchmark (12 æ¨¡å‹)ï¼šçº¦ 36 æ¬¡è°ƒç”¨
- å®Œæ•´ benchmark (40+ æ¨¡å‹)ï¼šçº¦ 120+ æ¬¡è°ƒç”¨

### é€Ÿç‡é™åˆ¶

å¦‚æœé‡åˆ°é€Ÿç‡é™åˆ¶é”™è¯¯ï¼Œå¢åŠ  `--delay` å‚æ•°ï¼š
```bash
python3 benchmark.py --models all --delay 3
```

---

## åœ¨ Web åº”ç”¨ä¸­ä½¿ç”¨å¤šæ¨¡å‹ / Using Multiple Models in Web App

å¯åŠ¨åº”ç”¨åï¼Œæ¨¡å‹é€‰æ‹©å™¨ä¼šæ˜¾ç¤ºæ‰€æœ‰å¯ç”¨æ¨¡å‹ï¼ŒæŒ‰æä¾›å•†åˆ†ç»„ï¼š

1. â­ **Recommended** - æ¨èçš„é¡¶çº§æ¨¡å‹
2. ğŸ¤– **OpenAI** - OpenAI å…¨ç³»åˆ—
3. ğŸ§  **Anthropic** - Claude ç³»åˆ—
4. ğŸ‡¨ğŸ‡³ **Chinese Models** - ä¸­å›½ä¸»æµæ¨¡å‹
5. ğŸ” **Google** - Gemini ç³»åˆ—
6. ğŸ”§ **Other** - å…¶ä»–æ¨¡å‹

---

## æ•…éšœæ’é™¤ / Troubleshooting

### æ¨¡å‹ä¸å¯ç”¨

æŸäº›æ¨¡å‹å¯èƒ½éœ€è¦ç‰¹æ®Šæƒé™æˆ–åœ¨æŸäº›åœ°åŒºä¸å¯ç”¨ã€‚å¦‚æœé‡åˆ°é”™è¯¯ï¼š
- æ£€æŸ¥æ™ºå¢å¢æ–‡æ¡£ç¡®è®¤æ¨¡å‹ ID
- å°è¯•å…¶ä»–ç±»ä¼¼æ¨¡å‹
- è”ç³»æ™ºå¢å¢å®¢æœ

### API é”™è¯¯

å¸¸è§é”™è¯¯åŠè§£å†³æ–¹æ¡ˆï¼š
- `401 Unauthorized` - æ£€æŸ¥ API å¯†é’¥
- `429 Too Many Requests` - å¢åŠ å»¶è¿Ÿæ—¶é—´
- `500 Server Error` - æ¨¡å‹å¯èƒ½æš‚æ—¶ä¸å¯ç”¨ï¼Œç¨åé‡è¯•

---

## æ€»ç»“ / Summary

âœ… **æ”¯æŒ 40+ ä¸ªæ¨¡å‹**  
âœ… **æ¶µç›–æ‰€æœ‰ä¸»æµ AI æä¾›å•†**  
âœ… **å®Œæ•´çš„ benchmark ç³»ç»Ÿ**  
âœ… **è¯¦ç»†çš„æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š**  
âœ… **çµæ´»çš„æµ‹è¯•é…ç½®**  
âœ… **ç»Ÿä¸€çš„ API å¯†é’¥**  

å¼€å§‹ä½ çš„ benchmark æµ‹è¯•å§ï¼ğŸš€

