# ğŸ”§ æ•…éšœæ’é™¤æŒ‡å—
# Troubleshooting Guide

## å¸¸è§é”™è¯¯åŠè§£å†³æ–¹æ¡ˆ

---

## âŒ Error: 'NoneType' object is not subscriptable

### é—®é¢˜æè¿°
åœ¨è¿è¡Œ Benchmark æˆ–ä½¿ç”¨æŸäº›æ¨¡å‹æ—¶å‡ºç°æ­¤é”™è¯¯ï¼š
```
Testing æ–‡å¿ƒä¸€è¨€ 4.0 (ernie-bot-4)... âœ— Error: 'NoneType' object is not subscriptable
```

### åŸå› åˆ†æ

è¿™ä¸ªé”™è¯¯é€šå¸¸ç”±ä»¥ä¸‹å‡ ä¸ªåŸå› å¯¼è‡´ï¼š

#### 1. **æ¨¡å‹ä¸å¯ç”¨æˆ–ä¸æ”¯æŒ**
æŸäº›æ¨¡å‹å¯èƒ½ï¼š
- åœ¨æ™ºå¢å¢å¹³å°ä¸Šä¸å¯ç”¨
- éœ€è¦ç‰¹æ®Šæƒé™æˆ–é¢å¤–é…ç½®
- æ¨¡å‹ ID ä¸æ­£ç¡®
- åœ¨æŸäº›åœ°åŒºä¸å¯ç”¨

#### 2. **API å“åº”ä¸ºç©º**
æ¨¡å‹è¿”å›äº†ç©ºå“åº”æˆ–æ ¼å¼ä¸ç¬¦åˆé¢„æœŸï¼š
```python
response.choices[0].message.content  # è¿”å› None
```

#### 3. **response_format ä¸æ”¯æŒ**
æŸäº›æ¨¡å‹ä¸æ”¯æŒ `response_format={"type": "json_object"}` å‚æ•°ã€‚

#### 4. **API é…ç½®é—®é¢˜**
- API å¯†é’¥æƒé™ä¸è¶³
- Base URL é…ç½®é”™è¯¯
- ç½‘ç»œè¿æ¥é—®é¢˜

---

### è§£å†³æ–¹æ¡ˆ

#### æ–¹æ¡ˆ 1ï¼šè·³è¿‡ä¸æ”¯æŒçš„æ¨¡å‹

ç¼–è¾‘ `app.py` æˆ– `benchmark.py`ï¼Œç§»é™¤æˆ–æ³¨é‡Šæ‰ä¸æ”¯æŒçš„æ¨¡å‹ï¼š

```python
# åœ¨ app.py çš„ /api/models ç«¯ç‚¹ä¸­
"chinese": [
    {"id": "qwen-max", "name": "é€šä¹‰åƒé—® Max", ...},
    {"id": "qwen-plus", "name": "é€šä¹‰åƒé—® Plus", ...},
    {"id": "qwen-turbo", "name": "é€šä¹‰åƒé—® Turbo", ...},
    # {"id": "ernie-bot-4", "name": "æ–‡å¿ƒä¸€è¨€ 4.0", ...},  # æš‚æ—¶æ³¨é‡Šæ‰
    {"id": "glm-4", "name": "ChatGLM-4", ...},
    {"id": "deepseek-chat", "name": "DeepSeek Chat", ...},
],
```

#### æ–¹æ¡ˆ 2ï¼šä½¿ç”¨å·²çŸ¥å¯ç”¨çš„æ¨¡å‹

åªæµ‹è¯•ç¡®è®¤å¯ç”¨çš„æ¨¡å‹ï¼š

```bash
# åªæµ‹è¯• OpenAI æ¨¡å‹
python3 benchmark.py --models openai

# æˆ–è€…æ‰‹åŠ¨æŒ‡å®šæ¨¡å‹åˆ—è¡¨
```

#### æ–¹æ¡ˆ 3ï¼šæ£€æŸ¥ API å¯†é’¥æƒé™

ç¡®è®¤ä½ çš„ API å¯†é’¥æ˜¯å¦æœ‰æƒé™è®¿é—®è¯¥æ¨¡å‹ï¼š

```bash
# æµ‹è¯• API è¿æ¥
python3 test_api.py
```

#### æ–¹æ¡ˆ 4ï¼šä¿®æ”¹æ¨¡å‹ ID

æŸäº›æ¨¡å‹çš„ ID å¯èƒ½ä¸åŒï¼Œå°è¯•å…¶ä»–å˜ä½“ï¼š

**æ–‡å¿ƒä¸€è¨€å¯èƒ½çš„ IDï¼š**
- `ernie-bot-4`
- `ernie-4.0`
- `ernie-bot-4.0`
- `ERNIE-Bot-4`

**é€šä¹‰åƒé—®å¯èƒ½çš„ IDï¼š**
- `qwen-max`
- `qwen-max-0428`
- `qwen-max-1201`

#### æ–¹æ¡ˆ 5ï¼šç§»é™¤ response_format å‚æ•°

æŸäº›æ¨¡å‹ä¸æ”¯æŒ JSON æ¨¡å¼ï¼Œå¯ä»¥ç§»é™¤è¿™ä¸ªå‚æ•°ï¼š

```python
# ä¿®æ”¹ benchmark.py æˆ– app.py
response = self.client.chat.completions.create(
    model=model_id,
    messages=[...],
    temperature=0.3,
    # response_format={"type": "json_object"}  # æ³¨é‡Šæ‰è¿™è¡Œ
)
```

ç„¶åæ‰‹åŠ¨è§£æ JSONï¼š
```python
try:
    result = json.loads(content)
except:
    # å°è¯•ä»æ–‡æœ¬ä¸­æå– JSON
    import re
    json_match = re.search(r'\{.*\}', content, re.DOTALL)
    if json_match:
        result = json.loads(json_match.group())
```

---

### å·²ä¿®å¤çš„æ”¹è¿›

æˆ‘å·²ç»åœ¨ä»£ç ä¸­æ·»åŠ äº†æ›´å¥½çš„é”™è¯¯å¤„ç†ï¼š

#### åœ¨ `app.py` ä¸­ï¼š

```python
# éªŒè¯å“åº”
if not response or not response.choices or len(response.choices) == 0:
    return jsonify({'error': 'No response from AI model'}), 500

if not response.choices[0].message or not response.choices[0].message.content:
    return jsonify({'error': 'Empty response from AI model'}), 500

# è§£æå“åº”
try:
    result = json.loads(response.choices[0].message.content)
except json.JSONDecodeError as e:
    return jsonify({'error': f'Invalid JSON response: {str(e)}'}), 500
```

#### åœ¨ `benchmark.py` ä¸­ï¼š

```python
# éªŒè¯å“åº”
if not response or not response.choices or len(response.choices) == 0:
    raise ValueError(f"No response from model {model_id}")

if not response.choices[0].message or not response.choices[0].message.content:
    raise ValueError(f"Empty response content from model {model_id}")

# è§£æç»“æœ
content = response.choices[0].message.content
if not content:
    raise ValueError(f"Response content is None from model {model_id}")

result = json.loads(content)
```

---

## ğŸ¯ æ¨èçš„æ¨¡å‹åˆ—è¡¨

### âœ… ç¡®è®¤å¯ç”¨çš„æ¨¡å‹

è¿™äº›æ¨¡å‹åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹éƒ½èƒ½æ­£å¸¸å·¥ä½œï¼š

**OpenAIï¼š**
- `gpt-4o` â­
- `gpt-4o-mini` â­
- `gpt-3.5-turbo` â­
- `gpt-4-turbo`

**Anthropicï¼š**
- `claude-3-5-sonnet-20241022` â­
- `claude-3-opus-20240229`
- `claude-3-haiku-20240307`

**Googleï¼š**
- `gemini-1.5-pro` â­
- `gemini-1.5-flash`

**DeepSeekï¼š**
- `deepseek-chat` â­
- `deepseek-coder`

**é˜¿é‡Œï¼š**
- `qwen-max` â­
- `qwen-plus`
- `qwen-turbo`

### âš ï¸ å¯èƒ½ä¸å¯ç”¨çš„æ¨¡å‹

è¿™äº›æ¨¡å‹å¯èƒ½éœ€è¦ç‰¹æ®Šé…ç½®æˆ–åœ¨æŸäº›æƒ…å†µä¸‹ä¸å¯ç”¨ï¼š

- `ernie-bot-4` (æ–‡å¿ƒä¸€è¨€ 4.0)
- `ernie-bot-turbo`
- `glm-4` (ChatGLM-4)
- `doubao-pro-32k` (è±†åŒ…)
- `baichuan2-turbo`
- `spark-3.5` (è®¯é£æ˜Ÿç«)
- `grok-beta`
- `llama-3-70b`

---

## ğŸ” è°ƒè¯•æ­¥éª¤

### 1. æµ‹è¯•å•ä¸ªæ¨¡å‹

```bash
# åˆ›å»ºæµ‹è¯•è„šæœ¬ test_single_model.py
cat > test_single_model.py << 'EOF'
from openai import OpenAI
import os

client = OpenAI(
    api_key=os.environ.get("ZZZ_API_KEY"),
    base_url=os.environ.get("ZZZ_BASE_URL", "https://api.zhizengzeng.com/v1/")
)

model_id = "ernie-bot-4"  # ä¿®æ”¹ä¸ºä½ è¦æµ‹è¯•çš„æ¨¡å‹

try:
    response = client.chat.completions.create(
        model=model_id,
        messages=[{"role": "user", "content": "Hello"}],
        temperature=0.3
    )
    print(f"âœ… {model_id} is available!")
    print(f"Response: {response.choices[0].message.content}")
except Exception as e:
    print(f"âŒ {model_id} error: {str(e)}")
EOF

python3 test_single_model.py
```

### 2. æŸ¥çœ‹è¯¦ç»†é”™è¯¯

åœ¨ `benchmark.py` æˆ– `app.py` ä¸­æ·»åŠ è°ƒè¯•è¾“å‡ºï¼š

```python
try:
    response = client.chat.completions.create(...)
    print(f"DEBUG: Response type: {type(response)}")
    print(f"DEBUG: Has choices: {hasattr(response, 'choices')}")
    if hasattr(response, 'choices'):
        print(f"DEBUG: Choices length: {len(response.choices)}")
        if len(response.choices) > 0:
            print(f"DEBUG: Message: {response.choices[0].message}")
except Exception as e:
    print(f"DEBUG: Exception: {type(e).__name__}: {str(e)}")
    import traceback
    traceback.print_exc()
```

### 3. æ£€æŸ¥ API é…ç½®

```bash
# éªŒè¯ç¯å¢ƒå˜é‡
echo "ZZZ_API_KEY: $ZZZ_API_KEY"
echo "ZZZ_BASE_URL: $ZZZ_BASE_URL"

# æµ‹è¯• API è¿æ¥
python3 test_api.py
```

---

## ğŸ“Š è¿è¡Œ Benchmark çš„æœ€ä½³å®è·µ

### 1. ä»å°èŒƒå›´å¼€å§‹

```bash
# å…ˆæµ‹è¯• OpenAI æ¨¡å‹ï¼ˆæœ€ç¨³å®šï¼‰
python3 benchmark.py --models openai

# å¦‚æœæˆåŠŸï¼Œå†æµ‹è¯•æ¨èæ¨¡å‹
python3 benchmark.py --models benchmark
```

### 2. å¢åŠ å»¶è¿Ÿé¿å…é™æµ

```bash
# å¢åŠ å»¶è¿Ÿåˆ° 2 ç§’
python3 benchmark.py --models benchmark --delay 2
```

### 3. æŸ¥çœ‹è¯¦ç»†æ—¥å¿—

```bash
# è¿è¡Œæ—¶é‡å®šå‘è¾“å‡º
python3 benchmark.py --models benchmark 2>&1 | tee benchmark.log
```

### 4. æ‰‹åŠ¨åˆ›å»ºå¯ç”¨æ¨¡å‹åˆ—è¡¨

ç¼–è¾‘ `models_list.py`ï¼ŒåªåŒ…å«ç¡®è®¤å¯ç”¨çš„æ¨¡å‹ï¼š

```python
def get_benchmark_models():
    """è·å–ç¡®è®¤å¯ç”¨çš„æ¨¡å‹"""
    return [
        {"id": "gpt-4o", "name": "GPT-4o", "provider": "OpenAI"},
        {"id": "gpt-3.5-turbo", "name": "GPT-3.5 Turbo", "provider": "OpenAI"},
        {"id": "claude-3-5-sonnet-20241022", "name": "Claude 3.5 Sonnet", "provider": "Anthropic"},
        {"id": "gemini-1.5-pro", "name": "Gemini 1.5 Pro", "provider": "Google"},
        {"id": "qwen-max", "name": "é€šä¹‰åƒé—® Max", "provider": "Alibaba"},
        {"id": "deepseek-chat", "name": "DeepSeek Chat", "provider": "DeepSeek"},
    ]
```

---

## ğŸ’¡ è”ç³»æ”¯æŒ

å¦‚æœé—®é¢˜æŒç»­å­˜åœ¨ï¼š

1. **æŸ¥çœ‹æ™ºå¢å¢æ–‡æ¡£**
   - è®¿é—®ï¼šhttps://doc.zhizengzeng.com/
   - æŸ¥çœ‹æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
   - ç¡®è®¤æ¨¡å‹ ID æ ¼å¼

2. **è”ç³»æ™ºå¢å¢å®¢æœ**
   - ç¡®è®¤ä½ çš„ API å¯†é’¥æƒé™
   - è¯¢é—®ç‰¹å®šæ¨¡å‹çš„å¯ç”¨æ€§
   - è·å–æ­£ç¡®çš„æ¨¡å‹ ID

3. **ä½¿ç”¨æ›¿ä»£æ¨¡å‹**
   - å¦‚æœæŸä¸ªæ¨¡å‹ä¸å¯ç”¨ï¼Œä½¿ç”¨åŒç±»å‹çš„å…¶ä»–æ¨¡å‹
   - ä¾‹å¦‚ï¼šæ–‡å¿ƒä¸€è¨€ä¸å¯ç”¨ â†’ ä½¿ç”¨é€šä¹‰åƒé—®æˆ– ChatGLM

---

## âœ… æ€»ç»“

### å¿«é€Ÿä¿®å¤æ­¥éª¤ï¼š

1. âœ… æ›´æ–°ä»£ç ï¼ˆå·²å®Œæˆï¼‰- æ·»åŠ äº†æ›´å¥½çš„é”™è¯¯å¤„ç†
2. âœ… è·³è¿‡ä¸å¯ç”¨çš„æ¨¡å‹
3. âœ… ä½¿ç”¨ç¡®è®¤å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨
4. âœ… å¢åŠ  API è°ƒç”¨å»¶è¿Ÿ
5. âœ… æŸ¥çœ‹è¯¦ç»†é”™è¯¯æ—¥å¿—

### æ¨èçš„æµ‹è¯•å‘½ä»¤ï¼š

```bash
# æœ€ç¨³å®šçš„æµ‹è¯•
python3 benchmark.py --models openai --delay 1

# å¦‚æœæˆåŠŸï¼Œå°è¯•æ›´å¤šæ¨¡å‹
python3 benchmark.py --models benchmark --delay 2
```

**ç°åœ¨é‡æ–°è¿è¡Œ Benchmark åº”è¯¥ä¼šæœ‰æ›´å¥½çš„é”™è¯¯æç¤ºï¼** ğŸš€

